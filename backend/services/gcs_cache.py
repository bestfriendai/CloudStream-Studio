from google.cloud import storage
from google.oauth2 import service_account
from google.auth.exceptions import RefreshError
from google.cloud.exceptions import NotFound
import logging
import os
import time
from typing import Optional, Dict
from threading import Lock
from collections import OrderedDict
from config import get_settings

logger = logging.getLogger(__name__)
settings = get_settings()


class MetadataCache:
    """è‡ªå®šç¾© Metadata å¿«å–ï¼Œæ”¯æ´å–®é …å¤±æ•ˆ"""
    
    def __init__(self, maxsize: int = 1000, ttl: int = 300):
        """
        Args:
            maxsize: æœ€å¤§å¿«å–æ•¸é‡
            ttl: å¿«å–å­˜æ´»æ™‚é–“ï¼ˆç§’ï¼‰
        """
        self._cache: OrderedDict[str, Dict] = OrderedDict()
        self._lock = Lock()
        self._maxsize = maxsize
        self._ttl = ttl
        self._hits = 0
        self._misses = 0
    
    def get(self, key: str) -> Optional[Dict]:
        """ç²å–å¿«å–é …ç›®"""
        with self._lock:
            if key not in self._cache:
                self._misses += 1
                return None
            
            item = self._cache[key]
            
            # æª¢æŸ¥æ˜¯å¦éæœŸ
            if time.time() - item['timestamp'] > self._ttl:
                del self._cache[key]
                self._misses += 1
                logger.debug(f"â° Cache expired: {key}")
                return None
            
            # ç§»åˆ°æœ€å¾Œï¼ˆLRUï¼‰
            self._cache.move_to_end(key)
            self._hits += 1
            
            return item['data']
    
    def set(self, key: str, data: Dict):
        """è¨­ç½®å¿«å–é …ç›®"""
        with self._lock:
            # å¦‚æœå·²å­˜åœ¨ï¼Œå…ˆåˆªé™¤
            if key in self._cache:
                del self._cache[key]
            
            # æª¢æŸ¥å®¹é‡
            while len(self._cache) >= self._maxsize:
                self._cache.popitem(last=False)
            
            self._cache[key] = {
                'data': data,
                'timestamp': time.time()
            }
    
    def invalidate(self, key: str) -> bool:
        """ä½¿ç‰¹å®šé …ç›®å¤±æ•ˆ"""
        with self._lock:
            if key in self._cache:
                del self._cache[key]
                logger.info(f"ğŸ—‘ï¸ Cache invalidated: {key}")
                return True
            return False
    
    def invalidate_prefix(self, prefix: str) -> int:
        """ä½¿æ‰€æœ‰ç¬¦åˆå‰ç¶´çš„é …ç›®å¤±æ•ˆ"""
        with self._lock:
            keys_to_delete = [k for k in self._cache if k.startswith(prefix)]
            for key in keys_to_delete:
                del self._cache[key]
            
            if keys_to_delete:
                logger.info(f"ğŸ—‘ï¸ Invalidated {len(keys_to_delete)} items with prefix: {prefix}")
            
            return len(keys_to_delete)
    
    def clear(self):
        """æ¸…é™¤æ‰€æœ‰å¿«å–"""
        with self._lock:
            count = len(self._cache)
            self._cache.clear()
            self._hits = 0
            self._misses = 0
            logger.info(f"ğŸ—‘ï¸ Cache cleared: {count} items")
    
    def get_info(self) -> Dict:
        """ç²å–å¿«å–çµ±è¨ˆ"""
        with self._lock:
            total = self._hits + self._misses
            return {
                'hits': self._hits,
                'misses': self._misses,
                'maxsize': self._maxsize,
                'currsize': len(self._cache),
                'hit_rate': self._hits / total if total > 0 else 0,
                'ttl': self._ttl
            }


class GCSConnectionPool:
    """GCS é€£æ¥æ± ï¼Œæ”¯æ´æœå‹™å¸³è™Ÿèªè­‰ã€è‡ªå‹•é‡é€£å’Œ metadata å¿«å–"""
    
    def __init__(self):
        self._client: Optional[storage.Client] = None
        self._bucket: Optional[storage.Bucket] = None
        self._credentials = None
        self._initialized = False
        self._lock = Lock()
        
        # âœ… ä½¿ç”¨è‡ªå®šç¾©å¿«å–ï¼ˆæ”¯æ´å–®é …å¤±æ•ˆï¼‰
        self._metadata_cache = MetadataCache(maxsize=1000, ttl=300)
        
    def _create_client(self) -> storage.Client:
        """å‰µå»º GCS clientï¼Œå„ªå…ˆä½¿ç”¨æœå‹™å¸³è™Ÿ"""
        try:
            # âœ… æ–¹æ³• 1: ä½¿ç”¨ Service Account JSON æª”æ¡ˆ
            credentials_path = settings.GOOGLE_APPLICATION_CREDENTIALS
            
            if credentials_path and os.path.exists(credentials_path):
                logger.info(f"ğŸ” Loading credentials from: {credentials_path}")
                
                # å¾ JSON æª”æ¡ˆè¼‰å…¥æ†‘è­‰
                self._credentials = service_account.Credentials.from_service_account_file(
                    credentials_path,
                    scopes=['https://www.googleapis.com/auth/cloud-platform']
                )
                
                # ä½¿ç”¨æ†‘è­‰å‰µå»º client
                client = storage.Client(
                    credentials=self._credentials,
                    project=settings.project_id
                )
                
                logger.info(f"âœ… GCS Client initialized with Service Account (Project: {settings.project_id})")
                return client
                
            else:
                # âœ… æ–¹æ³• 2: ä½¿ç”¨ç’°å¢ƒè®Šæ•¸ (fallback)
                if credentials_path:
                    logger.warning(f"âš ï¸ Service Account file not found: {credentials_path}")
                
                logger.info("ğŸ” Attempting to use Application Default Credentials...")
                
                client = storage.Client(project=settings.project_id)
                logger.info("âœ… GCS Client initialized with Application Default Credentials")
                return client
                
        except Exception as e:
            logger.error(f"âŒ Failed to create GCS client: {e}", exc_info=True)
            raise
    
    @property
    def client(self) -> storage.Client:
        """ç²å–æˆ–å‰µå»º GCS client"""
        if self._client is None:
            logger.info("ğŸ”Œ Initializing GCS client")
            self._client = self._create_client()
        
        return self._client
    
    def _reset_connection(self):
        """é‡ç½®é€£æ¥ï¼ˆç”¨æ–¼èªè­‰éæœŸæ™‚ï¼‰"""
        logger.warning("ğŸ”„ Resetting GCS connection")
        self._client = None
        self._bucket = None
        self._credentials = None
        self._initialized = False
        # æ¸…é™¤å¿«å–
        self._metadata_cache.clear()
    
    def get_bucket(self, bucket_name: str) -> storage.Bucket:
        """ç²å–æˆ–å‰µå»º bucket é€£æ¥ï¼Œæ”¯æ´è‡ªå‹•é‡é€£"""
        try:
            if self._bucket is None or self._bucket.name != bucket_name:
                logger.info(f"ğŸª£ Connecting to bucket: {bucket_name}")
                self._bucket = self.client.bucket(bucket_name)
                
                # é©—è­‰ bucket æ˜¯å¦å­˜åœ¨
                if not self._bucket.exists():
                    logger.error(f"âŒ Bucket does not exist: {bucket_name}")
                    raise ValueError(f"Bucket not found: {bucket_name}")
                
                logger.info(f"âœ… Connected to bucket: {bucket_name}")
                self._initialized = True
            
            return self._bucket
            
        except RefreshError as e:
            # âœ… èªè­‰éæœŸï¼Œé‡æ–°å‰µå»ºé€£æ¥
            logger.warning(f"âš ï¸ Authentication expired, attempting to reconnect: {e}")
            self._reset_connection()
            
            # é‡è©¦ä¸€æ¬¡
            logger.info("ğŸ”„ Retrying connection...")
            self._bucket = self.client.bucket(bucket_name)
            
            if not self._bucket.exists():
                raise ValueError(f"Bucket does not exist: {bucket_name}")
            
            logger.info(f"âœ… Reconnection successful: {bucket_name}")
            self._initialized = True
            return self._bucket
            
        except Exception as e:
            logger.error(f"âŒ Failed to get bucket: {e}", exc_info=True)
            raise
    
    def get_blob_metadata(self, bucket_name: str, blob_name: str) -> Optional[Dict]:
        """
        ç²å– blob metadataï¼ˆå¸¶å¿«å–ï¼‰
        
        Args:
            bucket_name: GCS bucket åç¨±
            blob_name: blob è·¯å¾‘
            
        Returns:
            metadata dict æˆ– Noneï¼ˆå¦‚æœä¸å­˜åœ¨ï¼‰
        """
        cache_key = f"{bucket_name}:{blob_name}"
        
        # âœ… å…ˆæª¢æŸ¥å¿«å–
        cached = self._metadata_cache.get(cache_key)
        if cached is not None:
            logger.debug(f"ğŸ“‹ Metadata cache HIT: {blob_name}")
            return cached
        
        # âœ… å¿«å–æœªå‘½ä¸­ï¼Œå¾ GCS ç²å–
        try:
            bucket = self.get_bucket(bucket_name)
            blob = bucket.blob(blob_name)
            
            # æª¢æŸ¥æ˜¯å¦å­˜åœ¨
            if not blob.exists():
                logger.debug(f"ğŸ“‚ Blob not found: {blob_name}")
                return None
            
            # é‡æ–°è¼‰å…¥ä»¥ç²å–æœ€æ–° metadata
            blob.reload()
            
            metadata = {
                'name': blob.name,
                'size': blob.size,
                'content_type': blob.content_type,
                'created': blob.time_created.isoformat() if blob.time_created else None,
                'updated': blob.updated.isoformat() if blob.updated else None,
                'md5_hash': blob.md5_hash,
                'etag': blob.etag,
                'public_url': f"https://storage.googleapis.com/{bucket_name}/{blob.name}",
                'metadata': blob.metadata or {}
            }
            
            # âœ… å„²å­˜åˆ°å¿«å–
            self._metadata_cache.set(cache_key, metadata)
            
            logger.debug(f"ğŸ“‹ Metadata cached: {blob_name} ({blob.size:,} bytes)")
            return metadata
            
        except RefreshError as e:
            # âœ… èªè­‰éæœŸï¼Œæ¸…é™¤å¿«å–ä¸¦é‡è©¦
            logger.warning(f"âš ï¸ Authentication expired, clearing cache and retrying: {e}")
            
            self._reset_connection()
            
            # é‡è©¦ä¸€æ¬¡
            try:
                bucket = self.get_bucket(bucket_name)
                blob = bucket.blob(blob_name)
                
                if not blob.exists():
                    return None
                
                blob.reload()
                
                metadata = {
                    'name': blob.name,
                    'size': blob.size,
                    'content_type': blob.content_type,
                    'created': blob.time_created.isoformat() if blob.time_created else None,
                    'updated': blob.updated.isoformat() if blob.updated else None,
                    'md5_hash': blob.md5_hash,
                    'etag': blob.etag,
                    'public_url': f"https://storage.googleapis.com/{bucket_name}/{blob.name}",
                    'metadata': blob.metadata or {}
                }
                
                self._metadata_cache.set(cache_key, metadata)
                
                logger.info(f"âœ… Retry successful, metadata retrieved: {blob_name}")
                return metadata
                
            except Exception as retry_error:
                logger.error(f"âŒ Retry failed: {retry_error}", exc_info=True)
                raise
            
        except NotFound:
            logger.debug(f"ğŸ“‚ File not found: {blob_name}")
            return None
            
        except Exception as e:
            logger.error(f"âŒ Failed to get metadata ({blob_name}): {e}", exc_info=True)
            raise
    
    def invalidate_metadata_cache(self, bucket_name: str, blob_name: str):
        """
        ä½¿ç‰¹å®š blob çš„ metadata å¿«å–å¤±æ•ˆ
        
        Args:
            bucket_name: GCS bucket åç¨±
            blob_name: blob è·¯å¾‘
        """
        cache_key = f"{bucket_name}:{blob_name}"
        self._metadata_cache.invalidate(cache_key)
    
    def invalidate_all_metadata_cache(self, bucket_name: str = None):
        """
        ä½¿æ‰€æœ‰ metadata å¿«å–å¤±æ•ˆ
        
        Args:
            bucket_name: å¦‚æœæŒ‡å®šï¼Œåªæ¸…é™¤è©² bucket çš„å¿«å–
        """
        if bucket_name:
            self._metadata_cache.invalidate_prefix(f"{bucket_name}:")
        else:
            self._metadata_cache.clear()
    
    def file_exists(self, bucket_name: str, blob_name: str) -> bool:
        """
        æª¢æŸ¥æª”æ¡ˆæ˜¯å¦å­˜åœ¨
        
        Args:
            bucket_name: GCS bucket åç¨±
            blob_name: blob è·¯å¾‘
            
        Returns:
            bool: æª”æ¡ˆæ˜¯å¦å­˜åœ¨
        """
        try:
            metadata = self.get_blob_metadata(bucket_name, blob_name)
            return metadata is not None
        except Exception as e:
            logger.error(f"âŒ Error checking file existence: {e}")
            return False
    
    def get_public_url(self, bucket_name: str, blob_name: str) -> str:
        """
        ç²å–æª”æ¡ˆçš„å…¬é–‹ URL
        
        Args:
            bucket_name: GCS bucket åç¨±
            blob_name: blob è·¯å¾‘
            
        Returns:
            str: å…¬é–‹ URL
        """
        return f"https://storage.googleapis.com/{bucket_name}/{blob_name}"
    
    def clear_cache(self):
        """æ¸…é™¤æ‰€æœ‰å¿«å–"""
        logger.info("ğŸ—‘ï¸ Clearing metadata cache")
        self._metadata_cache.clear()
    
    def get_cache_info(self) -> Dict:
        """
        ç²å–å¿«å–çµ±è¨ˆè³‡è¨Š
        
        Returns:
            Dict: å¿«å–çµ±è¨ˆ
        """
        return self._metadata_cache.get_info()
    
    def health_check(self) -> bool:
        """
        å¥åº·æª¢æŸ¥ï¼šé©—è­‰é€£æ¥æ˜¯å¦æ­£å¸¸
        
        Returns:
            bool: é€£æ¥æ˜¯å¦æ­£å¸¸
        """
        try:
            bucket = self.get_bucket(settings.GCS_BUCKET_NAME)
            # å˜—è©¦åˆ—å‡ºä¸€å€‹ blobï¼ˆé™åˆ¶ 1 å€‹ï¼‰
            list(bucket.list_blobs(max_results=1))
            logger.info("âœ… GCS connection health check passed")
            return True
        except Exception as e:
            logger.error(f"âŒ GCS connection health check failed: {e}")
            return False
    
    def get_status(self) -> Dict:
        """
        ç²å–é€£æ¥æ± ç‹€æ…‹
        
        Returns:
            Dict: ç‹€æ…‹è³‡è¨Š
        """
        return {
            'initialized': self._initialized,
            'bucket_name': self._bucket.name if self._bucket else None,
            'project_id': settings.project_id,
            'using_service_account': self._credentials is not None,
            'cache_info': self.get_cache_info()
        }


# ==================== å…¨åŸŸé€£æ¥æ± ï¼ˆå–®ä¾‹æ¨¡å¼ï¼‰====================

_connection_pool: Optional[GCSConnectionPool] = None


def get_connection_pool() -> GCSConnectionPool:
    """
    ç²å–å…¨åŸŸ GCS é€£æ¥æ± ï¼ˆå–®ä¾‹æ¨¡å¼ï¼‰
    
    Returns:
        GCSConnectionPool: é€£æ¥æ± å¯¦ä¾‹
    """
    global _connection_pool
    
    if _connection_pool is None:
        logger.info("ğŸš€ Initializing global GCS connection pool")
        _connection_pool = GCSConnectionPool()
        
        # åŸ·è¡Œå¥åº·æª¢æŸ¥
        try:
            if _connection_pool.health_check():
                logger.info("âœ… GCS connection pool initialized successfully")
            else:
                logger.warning("âš ï¸ GCS connection health check failed, but pool created")
        except Exception as e:
            logger.error(f"âŒ Failed to perform initial health check: {e}")
    
    return _connection_pool


def reset_connection_pool():
    """
    é‡ç½®å…¨åŸŸé€£æ¥æ± ï¼ˆç”¨æ–¼æ¸¬è©¦æˆ–éŒ¯èª¤æ¢å¾©ï¼‰
    """
    global _connection_pool
    
    if _connection_pool:
        logger.info("ğŸ”„ Resetting global GCS connection pool")
        _connection_pool._reset_connection()
        _connection_pool = None


def get_pool_status() -> Dict:
    """
    ç²å–é€£æ¥æ± ç‹€æ…‹
    
    Returns:
        Dict: ç‹€æ…‹è³‡è¨Š
    """
    if _connection_pool is None:
        return {
            'initialized': False,
            'message': 'Connection pool not initialized'
        }
    
    return _connection_pool.get_status()
